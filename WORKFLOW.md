# EXTRACTOR å®Œæ•´é‹è¡Œæµç¨‹æŒ‡å—

## ğŸ¯ æ•´é«”æ¦‚è¿°
```
è¨“ç·´éšæ®µ         æå–éšæ®µ          åˆ†é¡éšæ®µ
  â†“              â†“               â†“
main.py    â†’   extract.py   â†’  KNN0425.py
  â†“              â†“               â†“
è¨“ç·´æ¨¡å‹          æå–åµŒå…¥           åˆ†é¡çµæœ
```

---

## ğŸ“‹ è©³ç´°æµç¨‹

### **éšæ®µ 1ï¸âƒ£: è¨“ç·´ (Training)**

#### ğŸš€ **é‹è¡ŒæŒ‡ä»¤**
```bash
python main.py
```

#### ğŸ“ **`main.py` åŸ·è¡Œæµç¨‹**
```
main.py
    â”‚
    â”œâ”€ 1. è¨­å®š Device (GPU/CPU)
    â”‚   â””â”€ device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
    â”‚
    â”œâ”€ 2. åˆå§‹åŒ– ResNet æ¨¡å‹
    â”‚   â””â”€ model = ResNet()
    â”‚       â””â”€ èª¿ç”¨ model/resnet.py å®šç¾©çš„ ResNet æ¶æ§‹
    â”‚
    â”œâ”€ 3. å›ºå®šéš¨æ©Ÿç¨®å­
    â”‚   â””â”€ fixed_seed(seed=1206)  [åœ¨ utils/tool.py]
    â”‚
    â”œâ”€ 4. è¼‰å…¥è¨“ç·´è³‡æ–™
    â”‚   â””â”€ train_set, val_set = get_train_val_dataset(...)
    â”‚       â”‚
    â”‚       â””â”€ èª¿ç”¨ dataset/tool.py
    â”‚           â”‚
    â”‚           â””â”€ è¿”å› RxAgnosticCISDataset å¯¦ä¾‹
    â”‚               â”‚
    â”‚               â””â”€ è®€å– Q_matrix è³‡æ–™ (ä½ç½®: cfg['train_data_root'])
    â”‚                   â”‚
    â”‚                   â””â”€ ç›®éŒ„çµæ§‹:
    â”‚                       â”œâ”€ 0cm/
    â”‚                       â”‚  â”œâ”€ A1.mat, A2.mat, ...
    â”‚                       â”‚  â”œâ”€ B1.mat, B2.mat, ...
    â”‚                       â”‚  â””â”€ ...
    â”‚                       â”œâ”€ 0.1cm/
    â”‚                       â”‚  â””â”€ ...
    â”‚                       â””â”€ ...
    â”‚
    â”œâ”€ 5. å‰µå»º DataLoader
    â”‚   â”œâ”€ train_loader = DataLoader(train_set, batch_size=1024, shuffle=True, ...)
    â”‚   â””â”€ val_loader = DataLoader(val_set, batch_size=1024, shuffle=True, ...)
    â”‚
    â”œâ”€ 6. è¨­å®šå„ªåŒ–å™¨å’Œæå¤±å‡½æ•¸
    â”‚   â”œâ”€ optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
    â”‚   â”œâ”€ criterion = TripletMarginLoss(margin=0.5)
    â”‚   â”œâ”€ miner = TripletMarginMiner(margin=0.5, type_of_triplets="hard")
    â”‚   â””â”€ scheduler = ReduceLROnPlateau(optimizer, ...)
    â”‚
    â””â”€ 7. é–‹å§‹è¨“ç·´ (èª¿ç”¨ utils/tool.py ä¸­çš„ train() å‡½æ•¸)
        â”‚
        â””â”€ train(model, train_loader, val_loader, ...)
            â”‚
            â”œâ”€ å»ºç«‹ TensorBoard å¯«å…¥å™¨
            â”‚
            â””â”€ for epoch in range(num_epoch):  # è¿´åœˆ 2000 æ¬¡
                â”‚
                â”œâ”€ [è¨“ç·´éšæ®µ] model.train()
                â”‚   â”‚
                â”‚   â””â”€ for batch in train_loader:
                â”‚       â”œâ”€ anchor_CIS, anchor_tx = batch
                â”‚       â”œâ”€ out_anchor = model(anchor_CIS)  â† ResNet å‰å‘å‚³æ’­
                â”‚       â”œâ”€ hard_pairs = miner(out_anchor, anchor_tx)  â† æŒ–æ˜é›£æ¨£æœ¬å°
                â”‚       â”œâ”€ loss = criterion(out_anchor, anchor_tx, hard_pairs)  â† è¨ˆç®— Triplet Loss
                â”‚       â”œâ”€ optimizer.zero_grad()
                â”‚       â”œâ”€ loss.backward()
                â”‚       â””â”€ optimizer.step()
                â”‚
                â”œâ”€ [é©—è­‰éšæ®µ] model.eval()
                â”‚   â”‚
                â”‚   â””â”€ with torch.no_grad():
                â”‚       â””â”€ for batch in val_loader:
                â”‚           â”œâ”€ out_anchor = model(anchor_CIS)
                â”‚           â”œâ”€ loss = criterion(out_anchor, anchor_tx)
                â”‚           â””â”€ è¨˜éŒ„é©—è­‰æå¤±
                â”‚
                â”œâ”€ æ›´æ–°å­¸ç¿’ç‡
                â”‚   â””â”€ scheduler.step(val_loss)
                â”‚
                â”œâ”€ TensorBoard è¨˜éŒ„
                â”‚   â”œâ”€ train/loss
                â”‚   â”œâ”€ val/loss
                â”‚   â”œâ”€ train/learning_rate
                â”‚   â””â”€ triplet/num_train_triplet
                â”‚
                â””â”€ å­˜å„²æ¨¡å‹ (æ¯å€‹ epoch)
                    â”œâ”€ save/model_epoch.pt
                    â”œâ”€ save/optimizer_epoch.pt
                    â””â”€ save/best.pt  (ç•¶ val_loss æœ€ä½æ™‚)
```

#### ğŸ“Š **ResNet æ¶æ§‹** (åœ¨ `model/resnet.py`)
```
è¾“å…¥: [1, 1, H, W]  (batch_size, channels, height, width)
  â”‚
  â”œâ”€ Conv2d + BatchNorm + ReLU (å±¤å±¤å †ç–Š)
  â”œâ”€ BasicBlock / BottleneckBlock
  â”œâ”€ ResNet Residual é€£æ¥
  â”‚
  â””â”€ è¼¸å‡º: [batch_size, embedding_dim]  ä¾‹: [batch, 512]
```

#### âš™ï¸ **TripletMarginLoss åŸç†**
```
çµ¦å®š Triplet (anchor, positive, negative):
  - anchor: åƒè€ƒæ¨£æœ¬
  - positive: åŒé¡åˆ¥æ¨£æœ¬
  - negative: ä¸åŒé¡åˆ¥æ¨£æœ¬

Loss = max(d(anchor, positive) - d(anchor, negative) + margin, 0)
å…¶ä¸­:
  - d() = æ­å¹¾é‡Œå¾—è·é›¢
  - margin = 0.5

ç›®æ¨™: è®“ positive æ›´æ¥è¿‘ anchorï¼Œnegative é é›¢ anchor
```

---

### **éšæ®µ 2ï¸âƒ£: ç‰¹å¾µæå– (Feature Extraction)**

#### ğŸš€ **é‹è¡ŒæŒ‡ä»¤**
```bash
python extract.py
```

#### ğŸ“ **`extract.py` åŸ·è¡Œæµç¨‹**
```
extract.py
    â”‚
    â”œâ”€ 1. å®šç¾©è·¯å¾‘ (åœ¨å‡½æ•¸ extration(dis=1))
    â”‚   â”œâ”€ data_root: Q_matrix æ¸¬è©¦è³‡æ–™ (éœ€æ‰‹å‹•æŒ‡å®š)
    â”‚   â””â”€ folder_path: è¼¸å‡ºåµŒå…¥å‘é‡çš„ç›®éŒ„ (RFF/)
    â”‚
    â”œâ”€ 2. è¨­å®šè¨­å‚™
    â”‚   â””â”€ device = torch.device('cpu')  [å¯æ”¹ç‚º 'cuda:0']
    â”‚
    â”œâ”€ 3. è¼‰å…¥è¨“ç·´å®Œçš„æ¨¡å‹
    â”‚   â”œâ”€ model = ResNet()
    â”‚   â”œâ”€ model.load_state_dict(torch.load(saved_model_path))
    â”‚   â”‚   â””â”€ saved_model_path ä¾†è‡ª cfg.py
    â”‚   â””â”€ model.eval()  â† è¨­ç‚ºè©•ä¼°æ¨¡å¼
    â”‚
    â”œâ”€ 4. æº–å‚™è³‡æ–™é›†
    â”‚   â””â”€ dataset = CISDataset(data_root=data_root)
    â”‚       â””â”€ è®€å– Q_matrix .mat æ–‡ä»¶
    â”‚
    â””â”€ 5. é–‹å§‹æå– (è¿´åœˆéæ­·è³‡æ–™é›†)
        â”‚
        â””â”€ with torch.no_grad():  â† ä¸è¨ˆç®—æ¢¯åº¦ (ç¯€çœè¨˜æ†¶é«”)
            â”‚
            â””â”€ for i in range(len(dataset)):
                â”‚
                â”œâ”€ CIS, label, distance_folder = dataset[i]
                â”‚   â”‚
                â”‚   â””â”€ CIS.shape: [1, 1, H, W]
                â”‚       label: å¡ç‰‡åç¨± (e.g., "A1", "B5")
                â”‚       distance_folder: è·é›¢ (e.g., "0cm", "0.1cm")
                â”‚
                â”œâ”€ CIS = CIS.unsqueeze(0).to(device)  â† è®Šæˆ [1, 1, 1, H, W]
                â”‚
                â”œâ”€ embeddings = model(CIS).cpu().numpy()
                â”‚   â”‚
                â”‚   â””â”€ embeddings.shape: [1, embedding_dim]
                â”‚       ä¾‹: [1, 512]
                â”‚
                â”œâ”€ æŒ‰ distance_folder + label åˆ†çµ„å­˜å„²
                â”‚   â”‚
                â”‚   â””â”€ if (label æ”¹è®Š OR distance_folder æ”¹è®Š):
                â”‚       â”œâ”€ å°‡å‰ä¸€çµ„çš„åµŒå…¥å †ç–Šæˆ numpy array
                â”‚       â”‚   â””â”€ shape: [num_samples_of_this_label, embedding_dim]
                â”‚       â”‚       ä¾‹: [30, 512]  (å¦‚æœè©²æ¨™ç±¤æœ‰30å€‹æ¨£æœ¬)
                â”‚       â”‚
                â”‚       â””â”€ å­˜å„²ç‚º .npy æ–‡ä»¶
                â”‚           â””â”€ RFF/[distance]/[label].npy
                â”‚
                â””â”€ RFF.append(embeddings)  â† ç©ç´¯åŒä¸€ label çš„åµŒå…¥
```

#### ğŸ—‚ï¸ **è¼¸å‡ºçµæ§‹**
```
RFF/
â”œâ”€ 0cm/
â”‚  â”œâ”€ A1.npy  [shape: (30, 512)]  = 30 å€‹æ¨£æœ¬çš„åµŒå…¥å‘é‡
â”‚  â”œâ”€ A2.npy
â”‚  â”œâ”€ B1.npy
â”‚  â””â”€ ...
â”œâ”€ 0.1cm/
â”‚  â”œâ”€ A1.npy
â”‚  â””â”€ ...
â””â”€ ...
```

#### âš¡ **æ ¸å¿ƒä»£ç¢¼ç‰‡æ®µ**
```python
# æ²’æœ‰æ¢¯åº¦è¨ˆç®—ï¼ŒåŠ å¿«é€Ÿåº¦
with torch.no_grad():
    for i in range(len(dataset)):
        CIS, label, distance_folder = dataset[i]
        CIS = CIS.unsqueeze(0).to(device)
        
        # æ¨¡å‹å‰å‘å‚³æ’­ï¼Œè¼¸å‡ºåµŒå…¥å‘é‡
        embeddings = model(CIS).cpu().numpy()  # [1, 512]
        
        RFF.append(embeddings)
        
        # ç•¶ label æˆ– distance æ”¹è®Šæ™‚ï¼Œå­˜å„²å‰ä¸€çµ„çš„çµæœ
        if (previous_label != label or previous_distance != distance_folder):
            arr = np.stack(RFF, axis=0)  # [N, 512]
            np.save(f'RFF/{previous_distance}/{previous_label}.npy', arr)
```

---

### **éšæ®µ 3ï¸âƒ£: KNN åˆ†é¡ (Classification)**

#### ğŸš€ **é‹è¡ŒæŒ‡ä»¤**
```bash
python KNN0425.py
```

#### ğŸ“ **`KNN0425.py` åŸ·è¡Œæµç¨‹** (å‡è¨­)
```
KNN0425.py
    â”‚
    â”œâ”€ 1. è¼‰å…¥è¨“ç·´ç”¨çš„åµŒå…¥å‘é‡
    â”‚   â””â”€ å¾ RFF/ è®€å–æ‰€æœ‰ .npy æ–‡ä»¶
    â”‚       â””â”€ æ¨™ç±¤å°æ‡‰ (e.g., "A1" â†’ label 0)
    â”‚
    â”œâ”€ 2. æº–å‚™è¨“ç·´é›† & æ¸¬è©¦é›†
    â”‚   â”œâ”€ X_train: [N_train, 512]  åµŒå…¥å‘é‡
    â”‚   â”œâ”€ y_train: [N_train]  æ¨™ç±¤ç´¢å¼•
    â”‚   â””â”€ X_test, y_test åŒç†
    â”‚
    â”œâ”€ 3. è¨“ç·´ KNN æ¨¡å‹
    â”‚   â””â”€ knn = KNeighborsClassifier(n_neighbors=k)
    â”‚       â””â”€ è¨ˆç®—è·é›¢çŸ©é™£ (è¨“ç·´æ¨£æœ¬ä¹‹é–“çš„è·é›¢)
    â”‚
    â”œâ”€ 4. é æ¸¬æ¸¬è©¦é›†
    â”‚   â””â”€ y_pred = knn.predict(X_test)
    â”‚       â””â”€ å°æ¯å€‹æ¸¬è©¦æ¨£æœ¬ï¼Œæ‰¾æœ€è¿‘çš„ k å€‹è¨“ç·´æ¨£æœ¬
    â”‚           â””â”€ ç”¨å¤šæ•¸è¡¨æ±ºæ±ºå®šæ¨™ç±¤
    â”‚
    â””â”€ 5. è©•ä¼°æ•ˆæœ
        â”œâ”€ accuracy = accuracy_score(y_test, y_pred)
        â”œâ”€ precision, recall, f1 = precision_recall_fscore_support(...)
        â””â”€ æ‰“å°åˆ†é¡å ±å‘Š
```

---

### **éšæ®µ 3+ (å¯é¸): GRL è¨“ç·´å’Œæå–** 

#### ğŸš€ **é‹è¡ŒæŒ‡ä»¤ (Domain Adaptation)**
```bash
python GRLmain2.py    # è¨“ç·´å¸¶æœ‰ Gradient Reversal Layer
python extractGRL.py  # æå– GRL æ¨¡å‹çš„åµŒå…¥
```

#### ğŸ“ **GRL æ¶æ§‹** (åœ¨ `model/GRL_B.py`)
```
Q_matrix è¼¸å…¥
    â”‚
    â”œâ”€ ResNet (ç‰¹å¾µæå–å™¨)
    â”‚   â””â”€ è¼¸å‡º: [batch, 512] embedding
    â”‚
    â”œâ”€ [åˆ†æ”¯ 1] TX åˆ†é¡é ­
    â”‚   â”œâ”€ å…¨é€£æ¥å±¤
    â”‚   â””â”€ è¼¸å‡º: [batch, num_classes] logits
    â”‚
    â””â”€ [åˆ†æ”¯ 2] åŸŸåˆ†é¡é ­ (with GRL)
        â”œâ”€ Gradient Reversal Layer
        â”‚   â””â”€ alpha åƒæ•¸æ§åˆ¶åè½‰å¼·åº¦
        â”œâ”€ å…¨é€£æ¥å±¤
        â””â”€ è¼¸å‡º: [batch, num_domains] logits

ç›®æ¨™:
  - æœ€å¤§åŒ– TX åˆ†é¡ç²¾åº¦
  - æœ€å°åŒ–åŸŸåˆ†é¡ç²¾åº¦ (é˜²æ­¢éåº¦æ“¬åˆç‰¹å®šè·é›¢)
```

---

## ğŸ”‘ **é—œéµé…ç½®åƒæ•¸** (åœ¨ `cfg.py`)

```python
cfg = {
    # è³‡æ–™è·¯å¾‘
    'train_data_root': 'D:/åˆ/EXTRACTOR/dataset/0929_AF16_low1MHzDB/Q_matrix',
    'saved_model_path': 'D:/åˆ/EXTRACTOR/save/GRLGaps_0928_3dis_AF16/model_320.pt',
    
    # è¨“ç·´åƒæ•¸
    'batch_size': 1024,           # æ‰¹æ¬¡å¤§å°
    'epoch': 2000,                # è¨“ç·´è¼ªæ•¸
    'lr': 0.001,                  # å­¸ç¿’ç‡
    'margin': 0.5,                # Triplet Loss é‚Šè·
    'seed': 1206,                 # éš¨æ©Ÿç¨®å­
    
    # æ•¸æ“šåˆ†å‰²
    'split_ratio': 0.9,           # è¨“ç·´/é©—è­‰æ¯”ä¾‹
    'train_ratio': 0.8,
    'val_ratio': 0.1,
}
```

---

## ğŸ¬ **å®Œæ•´é‹è¡Œå·¥ä½œæµç¨‹**

### å ´æ™¯ A: å¾é ­è¨“ç·´

```bash
# æ­¥é©Ÿ 1: ç¢ºä¿ Q_matrix åœ¨æ­£ç¢ºä½ç½®
# è·¯å¾‘: D:/åˆ/EXTRACTOR/dataset/0929_AF16_low1MHzDB/Q_matrix/
#      â”œâ”€ 0cm/  (æˆ–å…¶ä»–è·é›¢)
#      â”‚  â”œâ”€ A1.mat
#      â”‚  â”œâ”€ A2.mat
#      â”‚  â””â”€ ...

# æ­¥é©Ÿ 2: ä¿®æ”¹ cfg.py çš„è·¯å¾‘
nano cfg.py
# ä¿®æ”¹: 'train_data_root' æŒ‡å‘ä½ çš„ Q_matrix è·¯å¾‘

# æ­¥é©Ÿ 3: è¨“ç·´æ¨¡å‹
python main.py
# è¼¸å‡º: ./save/model_0.pt, model_1.pt, ..., best.pt

# æ­¥é©Ÿ 4: æå–åµŒå…¥å‘é‡
python extract.py
# ä¿®æ”¹: extract.py ä¸­çš„ data_root (æ¸¬è©¦è³‡æ–™è·¯å¾‘)
#      folder_path (è¼¸å‡ºè·¯å¾‘)
# è¼¸å‡º: ./RFF/[distance]/[label].npy

# æ­¥é©Ÿ 5: KNN åˆ†é¡
python KNN0425.py
# è¼¸å‡º: åˆ†é¡ç²¾åº¦ã€F1 åˆ†æ•¸ç­‰
```

### å ´æ™¯ B: ä½¿ç”¨é è¨“ç·´æ¨¡å‹

```bash
# æ­¥é©Ÿ 1: ç›´æ¥æå– (ä½¿ç”¨å·²è¨“ç·´çš„æ¨¡å‹)
python extract.py
# ä¿®æ”¹: 
#   - data_root (ä½ çš„æ¸¬è©¦ Q_matrix è·¯å¾‘)
#   - saved_model_path (æŒ‡å‘å·²è¨“ç·´æ¨¡å‹)
#   - folder_path (è¼¸å‡ºè·¯å¾‘)

# æ­¥é©Ÿ 2: åˆ†é¡
python KNN0425.py
```

---

## ğŸ“Š **æ•¸æ“šæµå‘åœ–**

```
Raw Data (.mat)
    â”‚
    â”œâ”€ main.py è¨“ç·´éšæ®µ
    â”‚   â”œâ”€ è®€å– Q_matrix â†’ ResNet â†’ è¨ˆç®— Loss â†’ å„ªåŒ–åƒæ•¸
    â”‚   â””â”€ ä¿å­˜: ./save/best.pt
    â”‚
    â”œâ”€ extract.py æå–éšæ®µ
    â”‚   â”œâ”€ è®€å– Q_matrix â†’ ResNet(best.pt) â†’ åµŒå…¥å‘é‡
    â”‚   â””â”€ ä¿å­˜: ./RFF/[distance]/[label].npy
    â”‚
    â””â”€ KNN0425.py åˆ†é¡éšæ®µ
        â”œâ”€ è®€å– ./RFF/*.npy â†’ KNN æ¨¡å‹ â†’ é æ¸¬
        â””â”€ è¼¸å‡º: ç²¾åº¦ã€æ··æ·†çŸ©é™£ç­‰

```

---

## âš™ï¸ **å¸¸è¦‹å•é¡Œæ’æŸ¥**

| å•é¡Œ | åŸå›  | è§£æ±ºæ–¹æ¡ˆ |
|------|------|--------|
| `No module named 'mat73'` | ç¼ºå°‘ä¾è³´ | `pip install mat73 scipy` |
| `CUDA out of memory` | æ‰¹æ¬¡éå¤§æˆ– GPU ä¸è¶³ | æ¸›å°‘ `batch_size` æˆ–æ”¹ç”¨ CPU |
| `FileNotFoundError` | è·¯å¾‘éŒ¯èª¤ | æª¢æŸ¥ `cfg.py` ä¸­çš„è·¯å¾‘æ˜¯å¦æ­£ç¢º |
| `shape mismatch` | Q_matrix ç¶­åº¦ä¸ç¬¦ | ç¢ºä¿ Q_matrix çš„é«˜åº¦/å¯¬åº¦ä¸€è‡´ |
| `val_loss ä¸ä¸‹é™` | å­¸ç¿’ç‡å¤ªå°æˆ–æ•¸æ“šä¸è¶³ | å¢åŠ  `lr` æˆ–æª¢æŸ¥è¨“ç·´æ•¸æ“š |

---

## ğŸ’¾ **æª”æ¡ˆèªªæ˜**

```
EXTRACTOR/
â”œâ”€ main.py                â† â­ è¨“ç·´ä¸»ç¨‹åº
â”œâ”€ extract.py             â† â­ ç‰¹å¾µæå–
â”œâ”€ extractGRL.py          â† GRL ç‰¹å¾µæå– (å¯é¸)
â”œâ”€ KNN0425.py             â† KNN åˆ†é¡
â”œâ”€ GRLmain2.py            â† GRL è¨“ç·´ (å¯é¸)
â”œâ”€ cfg.py                 â† âš™ï¸  é…ç½®æ–‡ä»¶
â”œâ”€ cfg_ex.py              â† GRL é…ç½®
â”‚
â”œâ”€ model/
â”‚  â”œâ”€ resnet.py           â† ResNet æ¶æ§‹å®šç¾©
â”‚  â”œâ”€ GRL_B.py            â† GRL wrapper
â”‚  â””â”€ head.py             â† åˆ†é¡é ­
â”‚
â”œâ”€ dataset/
â”‚  â”œâ”€ tool.py             â† æ•¸æ“šåŠ è¼‰å·¥å…·
â”‚  â””â”€ CISDataset.py       â† æ•¸æ“šé›†é¡å®šç¾©
â”‚
â”œâ”€ utils/
â”‚  â”œâ”€ tool.py             â† è¨“ç·´å·¥å…· (train å‡½æ•¸)
â”‚  â””â”€ tool2.py            â† GRL è¨“ç·´å·¥å…·
â”‚
â”œâ”€ save/                  â† ğŸ—‚ï¸  å„²å­˜è¨“ç·´å¥½çš„æ¨¡å‹
â”‚  â”œâ”€ model_0.pt
â”‚  â”œâ”€ model_1.pt
â”‚  â””â”€ best.pt
â”‚
â””â”€ RFF/                   â† ğŸ—‚ï¸  å„²å­˜æå–çš„åµŒå…¥å‘é‡
    â”œâ”€ 0cm/
    â”‚  â”œâ”€ A1.npy
    â”‚  â””â”€ ...
    â””â”€ ...
```

---

## ğŸ“ **æ€»çµ: ä½ ç°åœ¨éœ€è¦åšä»€ä¹ˆ**

æ—¢ç„¶ä½ å·²ç¶“æœ‰ Q_matrix äº†:

```
1. âœ… ä¿®æ”¹ cfg.py
   â””â”€ 'train_data_root' æŒ‡å‘ä½ çš„ Q_matrix è·¯å¾‘

2. âœ… é‹è¡Œè¨“ç·´
   â””â”€ python main.py
   â””â”€ ç­‰å¾… ~2000 å€‹ epoch (å¯èƒ½éœ€è¦æ•¸å°æ™‚)

3. âœ… æå–åµŒå…¥å‘é‡
   â””â”€ python extract.py
   â””â”€ ä¿®æ”¹ data_root å’Œ folder_path

4. âœ… åˆ†é¡å’Œè©•ä¼°
   â””â”€ python KNN0425.py
   â””â”€ æŸ¥çœ‹ç²¾åº¦çµæœ
```

**ç¥ä½ æˆåŠŸï¼** ğŸš€
